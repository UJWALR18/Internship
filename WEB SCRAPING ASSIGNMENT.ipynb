{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "229242d4",
   "metadata": {},
   "source": [
    "# WEB SCRAPING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b409427b",
   "metadata": {},
   "source": [
    "# a python program to display all the header tags from wikipedia.org and make data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06f8cde7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Header Tag                           Text\n",
      "0         h1                      Main Page\n",
      "1         h1           Welcome to Wikipedia\n",
      "2         h2  From today's featured article\n",
      "3         h2               Did you know ...\n",
      "4         h2                    In the news\n",
      "5         h2                    On this day\n",
      "6         h2       Today's featured picture\n",
      "7         h2       Other areas of Wikipedia\n",
      "8         h2    Wikipedia's sister projects\n",
      "9         h2            Wikipedia languages\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/Main_Page\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "header_tags = []\n",
    "for i in range(1, 7):\n",
    "    tags = soup.find_all(f\"h{i}\")\n",
    "    for tag in tags:\n",
    "        header_tags.append((f\"h{i}\", tag.text.strip()))\n",
    "\n",
    "df = pd.DataFrame(header_tags, columns=[\"Header Tag\", \"Text\"])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac01ffcd",
   "metadata": {},
   "source": [
    "# a python program to display IMDB’s Top rated 50 movies’ data (i.e. name, rating, year of release)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3ca032fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Movie Titles  Year Rating\n",
      "0                            The Shawshank Redemption  1994    9.2\n",
      "1                                       The Godfather  1972    9.2\n",
      "2                                     The Dark Knight  2008    9.0\n",
      "3                               The Godfather Part II  1974    9.0\n",
      "4                                        12 Angry Men  1957    9.0\n",
      "5                                    Schindler's List  1993    8.9\n",
      "6       The Lord of the Rings: The Return of the King  2003    8.9\n",
      "7                                        Pulp Fiction  1994    8.8\n",
      "8   The Lord of the Rings: The Fellowship of the Ring  2001    8.8\n",
      "9                     Il buono, il brutto, il cattivo  1966    8.8\n",
      "10                                       Forrest Gump  1994    8.8\n",
      "11                                         Fight Club  1999    8.7\n",
      "12              The Lord of the Rings: The Two Towers  2002    8.7\n",
      "13                                          Inception  2010    8.7\n",
      "14                            The Empire Strikes Back  1980    8.7\n",
      "15                                         The Matrix  1999    8.7\n",
      "16                                         GoodFellas  1990    8.7\n",
      "17                    One Flew Over the Cuckoo's Nest  1975    8.6\n",
      "18                                              Se7en  1995    8.6\n",
      "19                               Shichinin no samurai  1954    8.6\n",
      "20                              It's a Wonderful Life  1946    8.6\n",
      "21                           The Silence of the Lambs  1991    8.6\n",
      "22                                Saving Private Ryan  1998    8.6\n",
      "23                                     Cidade de Deus  2002    8.6\n",
      "24                                       Interstellar  2014    8.6\n",
      "25                                    La vita è bella  1997    8.6\n",
      "26                                     The Green Mile  1999    8.6\n",
      "27                                          Star Wars  1977    8.5\n",
      "28                         Terminator 2: Judgment Day  1991    8.5\n",
      "29                                 Back to the Future  1985    8.5\n",
      "30                      Sen to Chihiro no kamikakushi  2001    8.5\n",
      "31                                        The Pianist  2002    8.5\n",
      "32                                             Psycho  1960    8.5\n",
      "33                                       Gisaengchung  2019    8.5\n",
      "34                                               Léon  1994    8.5\n",
      "35                                      The Lion King  1994    8.5\n",
      "36                                          Gladiator  2000    8.5\n",
      "37                                 American History X  1998    8.5\n",
      "38                                       The Departed  2006    8.5\n",
      "39                                       The Prestige  2006    8.5\n",
      "40                                           Whiplash  2014    8.5\n",
      "41                                 The Usual Suspects  1995    8.5\n",
      "42                                         Casablanca  1942    8.5\n",
      "43                                     Hotaru no haka  1988    8.5\n",
      "44                                            Seppuku  1962    8.5\n",
      "45                                   The Intouchables  2011    8.5\n",
      "46                                       Modern Times  1936    8.4\n",
      "47                       Once Upon a Time in the West  1968    8.4\n",
      "48                              Nuovo Cinema Paradiso  1988    8.4\n",
      "49                                        Rear Window  1954    8.4\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.imdb.com/chart/top/?ref_=nv_mv_250\"\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "results =soup.find_all('td')\n",
    "\n",
    "l1=[]\n",
    "for i in range(1, len(results),5)[0:50]:\n",
    "    if i== len(results)-1:\n",
    "        break\n",
    "    else:\n",
    "        name= results[i].text.strip().split(\".\")[-1].strip().split(\"\\n\")[0]\n",
    "        year= results[i].text.strip().split(\".\")[-1].strip().split(\"\\n\")[-1][1:-1]\n",
    "        rating= results[i+1].text.strip()\n",
    "        \n",
    "    l1.append([name,year,rating])    \n",
    "df=pd.DataFrame(l1,columns=['Movie Titles','Year','Rating'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764c06e3",
   "metadata": {},
   "source": [
    "# a python program to display IMDB’s Top rated 50 Indian movies’ data (i.e. name, rating, year of\n",
    "release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b09e64a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Movie Titles  Year Rating\n",
      "0   Ramayana: The Legend of Prince Rama  1993    8.6\n",
      "1            Rocketry: The Nambi Effect  2022    8.4\n",
      "2                               Nayakan  1987    8.4\n",
      "3                              Gol Maal  1979    8.4\n",
      "4                           777 Charlie  2022    8.4\n",
      "5                            Anbe Sivam  2003    8.4\n",
      "6                     Pariyerum Perumal  2018    8.4\n",
      "7                              Jai Bhim  2021    8.4\n",
      "8                           Apur Sansar  1959    8.4\n",
      "9                              3 Idiots  2009    8.4\n",
      "10                     Manichitrathazhu  1993    8.3\n",
      "11                                #Home  2021    8.3\n",
      "12                      Soorarai Pottru  2020    8.3\n",
      "13                         Black Friday  2004    8.3\n",
      "14                    Kumbalangi Nights  2019    8.3\n",
      "15                    C/o Kancharapalem  2018    8.3\n",
      "16                     Taare Zameen Par  2007    8.3\n",
      "17                             Kireedam  1989    8.3\n",
      "18                               Dangal  2016    8.3\n",
      "19                               Kaithi  2019    8.3\n",
      "20                               Jersey  2019    8.3\n",
      "21                                   96  2018    8.3\n",
      "22                          Maya Bazaar  1957    8.2\n",
      "23                            Natsamrat  2016    8.2\n",
      "24                           Drishyam 2  2021    8.2\n",
      "25                               Asuran  2019    8.2\n",
      "26                           Sita Ramam  2022    8.2\n",
      "27                         Thevar Magan  1992    8.2\n",
      "28                           Visaaranai  2015    8.2\n",
      "29                  Sarpatta Parambarai  2021    8.2\n",
      "30                           Thalapathi  1991    8.2\n",
      "31                         Nadodikkattu  1987    8.2\n",
      "32                      Pather Panchali  1955    8.2\n",
      "33                             Drishyam  2013    8.2\n",
      "34                         Thani Oruvan  2015    8.2\n",
      "35                   Jaane Bhi Do Yaaro  1983    8.2\n",
      "36                         Vada Chennai  2018    8.2\n",
      "37                            Aparajito  1956    8.2\n",
      "38                         Sardar Udham  2021    8.2\n",
      "39                    Khosla Ka Ghosla!  2006    8.2\n",
      "40                              Anniyan  2005    8.2\n",
      "41                             Ratsasan  2018    8.1\n",
      "42                        Chupke Chupke  1975    8.1\n",
      "43                   Gangs of Wasseypur  2012    8.1\n",
      "44                             Drishyam  2015    8.1\n",
      "45                              Peranbu  2018    8.1\n",
      "46                             Mahanati  2018    8.1\n",
      "47                       Bangalore Days  2014    8.1\n",
      "48                                Satya  1998    8.1\n",
      "49                               Premam  2015    8.1\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.imdb.com/india/top-rated-indian-movies/?sort=ir,desc&mode=simple&page=1\"\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "results =soup.find_all('td')\n",
    "\n",
    "l1=[]\n",
    "for i in range(1, len(results),5)[0:50]:\n",
    "    if i== len(results)-1:\n",
    "        break\n",
    "    else:\n",
    "        name= results[i].text.strip().split(\".\")[-1].strip().split(\"\\n\")[0]\n",
    "        year= results[i].text.strip().split(\".\")[-1].strip().split(\"\\n\")[-1][1:-1]\n",
    "        rating= results[i+1].text.strip()\n",
    "        \n",
    "    l1.append([name,year,rating])    \n",
    "df=pd.DataFrame(l1,columns=['Movie Titles','Year','Rating'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c37277",
   "metadata": {},
   "source": [
    "# python program to display list of respected former presidents of India(i.e. Name , Term ofoffice)\n",
    "from https://presidentofindia.nic.in/former-presidents.htm and make data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e784d27e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PresidentiaL List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nShri Ram Nath Kovind (birth - 1945)\\nTerm of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nShri Pranab Mukherjee (1935-2020)\\nTerm of O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nSmt Pratibha Devisingh Patil (birth - 1934)\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nDR. A.P.J. Abdul Kalam (1931-2015)\\nTerm of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nShri K. R. Narayanan (1920 - 2005)\\nTerm of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\\nDr Shankar Dayal Sharma (1918-1999)\\nTerm of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\nShri R Venkataraman (1910-2009)\\nTerm of Off...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\\nGiani Zail Singh (1916-1994)\\nTerm of Office...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\\nShri Neelam Sanjiva Reddy (1913-1996)\\nTerm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\\nDr. Fakhruddin Ali Ahmed (1905-1977)\\nTerm o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\\nShri Varahagiri Venkata Giri (1894-1980)\\nTe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\\nDr. Zakir Husain (1897-1969)\\nTerm of Office...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\\nDr. Sarvepalli Radhakrishnan (1888-1975)\\nTe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\\nDr. Rajendra Prasad (1884-1963) \\nTerm of Of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    PresidentiaL List\n",
       "0   \\nShri Ram Nath Kovind (birth - 1945)\\nTerm of...\n",
       "1   \\nShri Pranab Mukherjee (1935-2020)\\nTerm of O...\n",
       "2   \\nSmt Pratibha Devisingh Patil (birth - 1934)\\...\n",
       "3   \\nDR. A.P.J. Abdul Kalam (1931-2015)\\nTerm of ...\n",
       "4   \\nShri K. R. Narayanan (1920 - 2005)\\nTerm of ...\n",
       "5   \\nDr Shankar Dayal Sharma (1918-1999)\\nTerm of...\n",
       "6   \\nShri R Venkataraman (1910-2009)\\nTerm of Off...\n",
       "7   \\nGiani Zail Singh (1916-1994)\\nTerm of Office...\n",
       "8   \\nShri Neelam Sanjiva Reddy (1913-1996)\\nTerm ...\n",
       "9   \\nDr. Fakhruddin Ali Ahmed (1905-1977)\\nTerm o...\n",
       "10  \\nShri Varahagiri Venkata Giri (1894-1980)\\nTe...\n",
       "11  \\nDr. Zakir Husain (1897-1969)\\nTerm of Office...\n",
       "12  \\nDr. Sarvepalli Radhakrishnan (1888-1975)\\nTe...\n",
       "13  \\nDr. Rajendra Prasad (1884-1963) \\nTerm of Of..."
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "\n",
    "page=requests.get('https://presidentofindia.nic.in/former-presidents.htm')\n",
    "\n",
    "\n",
    "\n",
    "soup=BeautifulSoup(page.content)\n",
    "soup\n",
    "\n",
    "first_title=soup.find('h3')\n",
    "first_title\n",
    " \n",
    "\n",
    "first_title.text\n",
    "\n",
    "first_title=[]\n",
    "for i in soup.find_all('h3'):\n",
    "    first_title.append(i.text)\n",
    "first_title\n",
    "\n",
    "\n",
    "Term=soup.find('p')\n",
    "Term\n",
    "\n",
    "Term.text\n",
    "\n",
    "Term=[]\n",
    "for i in soup.find_all('p'):\n",
    "    Term.append(i.text)\n",
    "Term\n",
    "\n",
    "\n",
    "\n",
    "Detail=soup.find('div', class_=\"presidentListing\")\n",
    "Detail\n",
    "\n",
    "Detail.text\n",
    "\n",
    "\n",
    "\n",
    "Detail=[]\n",
    "for i in soup.find_all('div', class_=\"presidentListing\"):\n",
    "    Detail.append(i.text)\n",
    "Detail\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({\"PresidentiaL List\":Detail})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68425bb",
   "metadata": {},
   "source": [
    "# a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame\n",
    "    a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3ecb3fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Team Matches Points Rating\n",
      "0    Australia\\nAUS      35  3,965    113\n",
      "1        India\\nIND      47  5,294    113\n",
      "2   New Zealand\\nNZ      30  3,367    112\n",
      "3      England\\nENG      36  3,988    111\n",
      "4     Pakistan\\nPAK      25  2,649    106\n",
      "5  South Africa\\nSA      29  2,919    101\n",
      "6   Bangladesh\\nBAN      38  3,625     95\n",
      "7     Sri Lanka\\nSL      35  3,037     87\n",
      "8   West Indies\\nWI      43  3,105     72\n",
      "9  Afghanistan\\nAFG      20  1,419     71\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Send a GET request to the website\n",
    "url = 'https://www.icc-cricket.com/rankings/mens/team-rankings/odi'\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find the table containing the team rankings data\n",
    "table = soup.find('table', {'class': 'table'})\n",
    "\n",
    "# Extract the data from the table\n",
    "rows = table.find_all('tr')[1:11]\n",
    "data = []\n",
    "for row in rows:\n",
    "    cols = row.find_all('td')\n",
    "    team = cols[1].text.strip()\n",
    "    matches = cols[2].text.strip()\n",
    "    points = cols[3].text.strip()\n",
    "    rating = cols[4].text.strip()\n",
    "    data.append([team, matches, points, rating])\n",
    "\n",
    "# Create a Pandas data frame from the extracted data\n",
    "df = pd.DataFrame(data, columns=['Team', 'Matches', 'Points', 'Rating'])\n",
    "\n",
    "# Display the data frame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1e8712",
   "metadata": {},
   "source": [
    "# b) Top 10 ODI Batsmen along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "35a149b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Name Team Rating\n",
      "0             Babar Azam  PAK    887\n",
      "1  Rassie van der Dussen   SA    777\n",
      "2            Imam-ul-Haq  PAK    740\n",
      "3        Quinton de Kock   SA    740\n",
      "4           Shubman Gill  IND    738\n",
      "5           David Warner  AUS    726\n",
      "6            Virat Kohli  IND    719\n",
      "7           Rohit Sharma  IND    707\n",
      "8            Steve Smith  AUS    702\n",
      "9           Fakhar Zaman  PAK    699\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Send a GET request to the website\n",
    "url = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting'\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find the table containing the top 10 ODI batsmen data\n",
    "table = soup.find('table', {'class': 'table rankings-table'})\n",
    "\n",
    "# Extract the data from the table\n",
    "rows = table.find_all('tr')\n",
    "data = []\n",
    "for row in rows[1:11]:\n",
    "    cols = row.find_all('td')\n",
    "    name = cols[1].text.strip()\n",
    "    team = cols[2].text.strip()\n",
    "    rating = cols[3].text.strip()\n",
    "    data.append([name, team, rating])\n",
    "\n",
    "# Create a Pandas data frame from the extracted data\n",
    "df = pd.DataFrame(data, columns=['Name', 'Team', 'Rating'])\n",
    "\n",
    "# Display the data frame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2719ed47",
   "metadata": {},
   "source": [
    "# Top 10 ODI bowlers along with the records of their team and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8950e546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Player Team Rating\n",
      "0    Josh Hazlewood  AUS    705\n",
      "1       Trent Boult   NZ    701\n",
      "2    Mohammed Siraj  IND    691\n",
      "3    Mitchell Starc  AUS    686\n",
      "4       Rashid Khan  AFG    659\n",
      "5        Adam Zampa  AUS    652\n",
      "6    Shaheen Afridi  PAK    641\n",
      "7  Mujeeb Ur Rahman  AFG    637\n",
      "8   Shakib Al Hasan  BAN    636\n",
      "9        Matt Henry   NZ    635\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Send a GET request to the website\n",
    "url = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling'\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find the table containing the ODI bowlers' data\n",
    "table = soup.find('table', {'class': 'table rankings-table'})\n",
    "\n",
    "# Extract the data from the table\n",
    "rows = table.find_all('tr')\n",
    "data = []\n",
    "for row in rows[1:11]:\n",
    "    cols = row.find_all('td')\n",
    "    player = cols[1].text.strip()\n",
    "    team = cols[2].text.strip()\n",
    "    rating = cols[3].text.strip()\n",
    "    data.append([player, team, rating])\n",
    "\n",
    "# Create a Pandas data frame from the extracted data\n",
    "df = pd.DataFrame(data, columns=['Player', 'Team', 'Rating'])\n",
    "\n",
    "# Display the data frame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2371636",
   "metadata": {},
   "source": [
    "# a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame\n",
    "a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8109aac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Team Matches Points Rating\n",
      "0    Australia\\nAUS      21  3,603    172\n",
      "1      England\\nENG      28  3,342    119\n",
      "2  South Africa\\nSA      26  3,098    119\n",
      "3        India\\nIND      27  2,820    104\n",
      "4   New Zealand\\nNZ      25  2,553    102\n",
      "5   West Indies\\nWI      27  2,535     94\n",
      "6   Bangladesh\\nBAN      13    983     76\n",
      "7     Thailand\\nTHA       8    572     72\n",
      "8     Pakistan\\nPAK      27  1,678     62\n",
      "9     Sri Lanka\\nSL       8    353     44\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Send a GET request to the website\n",
    "url = 'https://www.icc-cricket.com/rankings/womens/team-rankings/odi'\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find the table containing the women's ODI team rankings data\n",
    "table = soup.find('table', {'class': 'table'})\n",
    "\n",
    "# Extract the data from the table\n",
    "rows = table.find_all('tr')\n",
    "data = []\n",
    "for row in rows[1:11]:\n",
    "    cols = row.find_all('td')\n",
    "    team = cols[1].text.strip()\n",
    "    matches = cols[2].text.strip()\n",
    "    points = cols[3].text.strip()\n",
    "    rating = cols[4].text.strip()\n",
    "    data.append([team, matches, points, rating])\n",
    "\n",
    "# Create a Pandas data frame from the extracted data\n",
    "df = pd.DataFrame(data, columns=['Team', 'Matches', 'Points', 'Rating'])\n",
    "\n",
    "# Display the data frame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efda38c",
   "metadata": {},
   "source": [
    "# b) Top 10 women’s ODI Batting players along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ba3c29ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Player Team Rating\n",
      "0         Alyssa Healy  AUS    762\n",
      "1          Beth Mooney  AUS    754\n",
      "2      Laura Wolvaardt   SA    732\n",
      "3       Natalie Sciver  ENG    731\n",
      "4          Meg Lanning  AUS    717\n",
      "5     Harmanpreet Kaur  IND    716\n",
      "6      Smriti Mandhana  IND    714\n",
      "7       Rachael Haynes  AUS    680\n",
      "8  Chamari Athapaththu   SL    655\n",
      "9    Amy Satterthwaite   NZ    641\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Send a GET request to the website\n",
    "url = 'https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting'\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find the table containing the women's ODI batting players' data\n",
    "table = soup.find('table', {'class': 'table rankings-table'})\n",
    "\n",
    "# Extract the data from the table\n",
    "rows = table.find_all('tr')\n",
    "data = []\n",
    "for row in rows[1:11]:\n",
    "    cols = row.find_all('td')\n",
    "    name = cols[1].text.strip()\n",
    "    team = cols[2].text.strip()\n",
    "    rating = cols[3].text.strip()\n",
    "    data.append([name, team, rating])\n",
    "\n",
    "# Create a Pandas data frame from the extracted data\n",
    "df = pd.DataFrame(data, columns=['Player', 'Team', 'Rating'])\n",
    "\n",
    "# Display the data frame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8007a4a",
   "metadata": {},
   "source": [
    "# c) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "74d03e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Name Team Rating\n",
      "0   Hayley Matthews   WI    373\n",
      "1    Natalie Sciver  ENG    371\n",
      "2      Ellyse Perry  AUS    366\n",
      "3    Marizanne Kapp   SA    349\n",
      "4       Amelia Kerr   NZ    336\n",
      "5     Deepti Sharma  IND    322\n",
      "6  Ashleigh Gardner  AUS    292\n",
      "7     Jess Jonassen  AUS    250\n",
      "8          Nida Dar  PAK    232\n",
      "9    Jhulan Goswami  IND    214\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Send a GET request to the website\n",
    "url = 'https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder'\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find the table containing the top 10 all-rounders' data\n",
    "table = soup.find('table', {'class': 'table'})\n",
    "\n",
    "# Extract the data from the table\n",
    "rows = table.find_all('tr')\n",
    "data = []\n",
    "for row in rows[1:11]:\n",
    "    cols = row.find_all('td')\n",
    "    name = cols[1].text.strip()\n",
    "    team = cols[2].text.strip()\n",
    "    rating = cols[3].text.strip()\n",
    "    data.append([name, team, rating])\n",
    "\n",
    "# Create a Pandas data frame from the extracted data\n",
    "df = pd.DataFrame(data, columns=['Name', 'Team', 'Rating'])\n",
    "\n",
    "# Display the data frame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c34627e",
   "metadata": {},
   "source": [
    "# Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world and\n",
    "make data frame\n",
    "i) Headline\n",
    "ii) Time\n",
    "iii) News Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87f8362b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Headline, Time, News Link]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.cnbc.com/world/?region=world'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "headlines = []\n",
    "times = []\n",
    "links = []\n",
    "\n",
    "for article in soup.find_all('div', class_='Card-title'):\n",
    "    headline = article.find('a').get_text(strip=True)\n",
    "    link = article.find('a')['href']\n",
    "    time = article.find('time', class_='Card-time')['datetime']\n",
    "    \n",
    "    headlines.append(headline)\n",
    "    links.append(link)\n",
    "    times.append(time)\n",
    "\n",
    "df = pd.DataFrame({'Headline': headlines, 'Time': times, 'News Link': links})\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dfe854",
   "metadata": {},
   "source": [
    "# Write a python program to scrape the details of most downloaded articles from AI in last 90\n",
    "days.https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\n",
    "Scrape below mentioned details and make data framei) Paper Title\n",
    "ii) Authors\n",
    "iii) Published Date\n",
    "iv) Paper URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4573b5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Paper Title, Authors, Published Date, Paper URL]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles?fromDate=2022-02-01&toDate=2022-04-30\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "articles = soup.find_all(\"div\", {\"class\": \"pod-listing-header\"})\n",
    "\n",
    "data = []\n",
    "\n",
    "for article in articles:\n",
    "    title = article.find(\"a\").text\n",
    "    url = article.find(\"a\")[\"href\"]\n",
    "    authors = article.find(\"ul\", {\"class\": \"authors\"}).text.strip()\n",
    "    date = article.find(\"span\", {\"class\": \"date\"}).text.strip()\n",
    "\n",
    "    data.append([title, authors, date, url])\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"Paper Title\", \"Authors\", \"Published Date\", \"Paper URL\"])\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484041a6",
   "metadata": {},
   "source": [
    "# Write a python program to scrape mentioned details from dineout.co.in and make data framei) Restaurant name\n",
    "ii) Cuisine\n",
    "iii) Location\n",
    "iv) Ratings\n",
    "v) Image URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec6bd159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Restaurant Name Cuisine                                      Location  \\\n",
      "0              N/A     N/A                Connaught Place, Central Delhi   \n",
      "1              N/A     N/A  Scindia House,Connaught Place, Central Delhi   \n",
      "2              N/A     N/A        M-Block,Connaught Place, Central Delhi   \n",
      "3              N/A     N/A                Connaught Place, Central Delhi   \n",
      "4              N/A     N/A                Connaught Place, Central Delhi   \n",
      "5              N/A     N/A                Connaught Place, Central Delhi   \n",
      "6              N/A     N/A                Connaught Place, Central Delhi   \n",
      "7              N/A     N/A                Connaught Place, Central Delhi   \n",
      "8              N/A     N/A        F-Block,Connaught Place, Central Delhi   \n",
      "9              N/A     N/A                Connaught Place, Central Delhi   \n",
      "10             N/A     N/A                Connaught Place, Central Delhi   \n",
      "11             N/A     N/A                Connaught Place, Central Delhi   \n",
      "12             N/A     N/A                Connaught Place, Central Delhi   \n",
      "13             N/A     N/A        M-Block,Connaught Place, Central Delhi   \n",
      "14             N/A     N/A                Connaught Place, Central Delhi   \n",
      "15             N/A     N/A                Connaught Place, Central Delhi   \n",
      "16             N/A     N/A                Connaught Place, Central Delhi   \n",
      "17             N/A     N/A                Connaught Place, Central Delhi   \n",
      "18             N/A     N/A        M-Block,Connaught Place, Central Delhi   \n",
      "19             N/A     N/A                Connaught Place, Central Delhi   \n",
      "20             N/A     N/A                Connaught Place, Central Delhi   \n",
      "\n",
      "   Ratings Image URL  \n",
      "0      N/A       N/A  \n",
      "1      N/A       N/A  \n",
      "2      N/A       N/A  \n",
      "3      N/A       N/A  \n",
      "4      N/A       N/A  \n",
      "5      N/A       N/A  \n",
      "6      N/A       N/A  \n",
      "7      N/A       N/A  \n",
      "8      N/A       N/A  \n",
      "9      N/A       N/A  \n",
      "10     N/A       N/A  \n",
      "11     N/A       N/A  \n",
      "12     N/A       N/A  \n",
      "13     N/A       N/A  \n",
      "14     N/A       N/A  \n",
      "15     N/A       N/A  \n",
      "16     N/A       N/A  \n",
      "17     N/A       N/A  \n",
      "18     N/A       N/A  \n",
      "19     N/A       N/A  \n",
      "20     N/A       N/A  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.dineout.co.in/delhi-restaurants\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "restaurants = soup.find_all(\"div\", {\"class\": \"restnt-info\"})\n",
    "\n",
    "data = []\n",
    "\n",
    "for restaurant in restaurants:\n",
    "    name_elem = restaurant.find(\"div\", {\"class\": \"restnt-name\"})\n",
    "    if name_elem is not None:\n",
    "        name = name_elem.text.strip()\n",
    "    else:\n",
    "        name = \"N/A\"\n",
    "    \n",
    "    cuisine_elem = restaurant.find(\"div\", {\"class\": \"restnt-cuisine\"})\n",
    "    if cuisine_elem is not None:\n",
    "        cuisine = cuisine_elem.text.strip()\n",
    "    else:\n",
    "        cuisine = \"N/A\"\n",
    "    \n",
    "    location_elem = restaurant.find(\"div\", {\"class\": \"restnt-loc\"})\n",
    "    if location_elem is not None:\n",
    "        location = location_elem.text.strip()\n",
    "    else:\n",
    "        location = \"N/A\"\n",
    "    \n",
    "    rating_elem = restaurant.find(\"span\", {\"class\": \"rat-dig\"})\n",
    "    if rating_elem is not None:\n",
    "        rating = rating_elem.text.strip()\n",
    "    else:\n",
    "        rating = \"N/A\"\n",
    "    \n",
    "    image_elem = restaurant.find(\"div\", {\"class\": \"restnt-thumb\"})\n",
    "    if image_elem is not None:\n",
    "        image_url = image_elem[\"data-original\"]\n",
    "    else:\n",
    "        image_url = \"N/A\"\n",
    "    \n",
    "    data.append([name, cuisine, location, rating, image_url])\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"Restaurant Name\", \"Cuisine\", \"Location\", \"Ratings\", \"Image URL\"])\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffcfa7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
